\section{Cues\label{Cues}}
\paragraph{}
Seeing stereo is not only based on binocular stereopsis.There are several aspects of the visual impression that allow the perception of depth. Common depth cues include accommodation, aerial perspective, binocular disparity, convergence, height in visual field, motion perspective, occlusion, relative size, and relative density. In addition others have been suggested, such as linear perspective, light and shading and texture gradients.%, kinetic depth, kinetic occlusion and disocclusion, and gravity.

Cutting and Vishton\cite{DepthCues} analyzed nine of these depth cues to asses their relative strength. Those cues will be described in the following paragraphs, and their reproduction or elimination on screen in a digitally generated scene is discussed. The use of \textit{OpenGL} or a similar technology is assumed, techniques like ray-tracing or vector based painting may require different methods. A summary can be found in table \ref{DepthCuesTable}.


\subsection{Projection based cues}
\paragraph{}
These cues are caused by the way the 3D world gets projected onto the 2D surface of the retina.
Even though the reason that each of them exists is the same, the way they are evaluated and their reproduction is different.

Most projections\cite{proj} that are in use, map a ray in the world space onto a single point in the image space. \textit{Parallel Projection}\cite{parallel} and \textit{Perspective Projection}\cite{perspective} are the most commonly used methods. Real optics use a projection similar to perspective projection.

Since all the following cues are generated by the same cause, enabling and disabling each is not possible in a consistent way. There are two basic ways to get partial individual control despite this: Compensate  the perspective projection of the camera by removing cues, or  adding cues to a parallel projection. Careless use of either method can cause conflicts such as pinning, rivalry, or the inability to fuse the image.
Using two cameras might require depth ordering, since the depth buffer has to be invalidated.


\subsubsection{Relative size}
\paragraph{Description}
The size of objects relative to each other is a strong clue for their distance, but it requires knowledge or assumptions about the size of an object. Due to the \textit{perspective projection}, objects further away from a viewer take up less space in it's field-of-view. When seeing a human, it's distance can be estimated fairly accurately.

Seeing an unknown object requires comparisons with other objects in the scene. Upon seeing a number of cubes with different perceived sizes, and without prior knowledge of their size, one could assume similarity in size, and derive depth relations between them.

\paragraph{Reproduction}
Relative size only works when the perceived size of an object changes with it's distance. Using a perspective camera is an easy way to do this. When creating an artificial image, the size change can also be simulated by non-uniformly scaling objects based on their distance to the camera. If the whole object is considered as a single entity, artefacts might occur. In the case of OpenGL or most RayTracers, both parallel and perspective cameras are available.

\paragraph{Non-reproduction}
If the size of objects is not intended to change with their distance from the viewer, either choosing a parallel projection or compensating the projection based scaling by scaling the object size is needed. This causes visual distortions, if the object is embedded in a scene that is subject to relative size.


\subsubsection{Relative density}
\paragraph{Description}
Relative density is closely related to relative size. It concerns the projected density of objects, which are distributed regularly. When such a group of objects change in depth, or take up different depth areas, their change in perceived density yield information about the depth change.

\paragraph{Reproduction}
If a perspective projection is used, relative density changes are calculated correctly. Introducing relative density clues into a scene that is rendered with a parallel projection requires non uniform scaling.

\paragraph{Non-reproduction}
Eliminating the relative depth cue from part of a scene that is parallel projected requires non uniform scaling of a group of objects. Both the position relative to each other, and the size relative to each other of the objects has to change.


\subsubsection{Motion perspective}
\paragraph{Description}
Motion perspective is closely related with relative size and relative density. When moving and looking sideways, objects seem to move into the opposing direction. Objects that are far move much slower than objects that are close. When passing objects, their relative ordering can even change: A mountain that was on the right side of a tree can be seen on it's left side. This is caused by the projection into image space, which makes the space far away appear smaller, and therefore objects moving in this space slower.

\paragraph{Reproduction}
As with the other projection based clues it appears naturally if a perspective projection is used. Without this, it can still be reproduced by moving objects at a velocity scaled with the distance to the camera.

\paragraph{Non-reproduction}
Compensating motion perspective in a perspective scene requires the scaling of the embedded space, or the movement speed relative to the camera. This can lead to inconsistencies with other parts of the image.


\subsubsection{Height in visual field}
\paragraph{Description}
The bottom parts of objects that are touching the ground can be seen at the same place in the retina as the part of the floor they rest on. This is caused by the projection from the world into image space. The assumption are that the objects are touching the ground, that the ground is reasonably even, and that the viewer is perpendicular and above to the floor plane.

\paragraph{Reproduction}
Reproducing changes of objects in the height in visual field is fairly straight forward. The effect can be achieved by use of a projection that fulfills this property, such as a perspective projection, or some parallel projections. Or by simply translating objects in image space. Care has to be taken to not cause visual artefacts such as pinning.

\paragraph{Non-reproduction}
Eliminating the effect of the projection on the height in the visual field is straight forward. A projection that maps the floor plane on one single line in image space also maps the bottom of all objects on that plane. Objects can be shifted in image space to compensate for the projection. Raising objects so that they float above the ground is unproblematic, but moving them below ground either leads to occlusion, or depth conflicts.


\subsubsection{Convergence}
\paragraph{Description}
When moving a camera in a plane, the camera has to rotate to keep an object in the center of the image. The same is the case when using two cameras, or two eyes. Keeping a real object in focus will lead to converging eyes, since they have to point inwards, or for objects at infinitely long distance have to be parallel. The amount of convergence allows judging the distance. This is similar to the method of triangulation\cite{triangulation} used in navigation. Since the eye distance of humans is about 65mm, only close objects can be judged reliable.

Convergence \textit{(Proprioception)}is very closely related to height-of-fiel, motion parallax and binocular stereopsis, since it is created by the same effect. The way humans perceive it is very different.

\paragraph{Reproduction}
Reproducing convergence clues requires the creation of separate images for each eye. It comes natural with perspective projections and two cameras. Alternatively, the shift of paralaxe can also be simulated just by shifting the object horizontally depending on it's distance of the camera.

\paragraph{Non-reproduction}
Not reproducing convergence clues either requires to not use a perspective (or converged) projection, or to compensate the movement in paralaxe by moving the object horizontally in the scene depending on the camera distance.


\subsubsection{Binocular disparity and stereopsis}
\paragraph{Description}
Binocular stereopsis is similar to convergence, but it is based on the perception of the same object from two viewpoints, and analyising the differences. To be effective, the cameras have to be at different positions relative to each other. Adult human eyes are separated by about 65mm. Perceiving from different points of view is also closely related with motion perspective, and the same strategies can be applied to it.

\paragraph{Reproduction}
Reproducing binocular disparities that can be fused for binocular stereopsis is easy with two parallel cameras with perspective projection, or converged cameras with parallel/perspective projection.
Achieving the same effect by horizontally shifting object positions is possible, but suffers from several drawbacks. Objects will appear to be flat \textit{(cardboarding)}. Shifting objects horizontally is also used to create other stereo cues, so they will clash.

\paragraph{Non-reproduction}
Removing binocular stereopsis in a scene is fairly simple, reducing the camera separation to zero achieves it with little side effects.


\subsection{Other cues}
\paragraph{}
The following cues are not dependent on each other, or the projection of the scene, and can therefore be easier enable and disabled individually.

\subsubsection{Occlusion}
\paragraph{Description}
Objects that are in front of other objects relative to the viewer are perceived to occlude the object behind. Even transparent or translucent objects often change the appearance of objects they occlude. This allows to infer depth ordering of objects. This clue is very strong, and it's range is the longest of all depth cues. It does however not allow to judge the distance between objects.

\paragraph{Reproduction}
Reproducing this depth clue digitally requires extra work, since most output media do not have a notion of depth. A traditional approach is the Painter's Algorithm\cite{painters}. Objects are ordered by depth and drawn from far to close. Ordering objects has performance implications, and is not always possible.
A newer method that does not require sorting is the Depth Buffer\cite{zbuffer} (also known as Z-Buffer). For every pixel it's associated depth value is stored. New objects only replace pixels further away.

\paragraph{Non-reproduction}
Not reproducing this clue is fairly straight forward. Disabling the depth buffer allows ordering objects according to preferred depth appearance, independently of their actual depth coordinates. Objects that are both behind and in front of an other object have to be segmented into pieces. This is most commonly the case when objects intersect.

Objects that consist of several surfaces might require internal ordering to appear correct, which is expensive. One way to resolve this problem is to clear the depth buffer after every object drawing. Depending on the size of the image this might be costly also.


\subsubsection{Aerial perspective}
\paragraph{Description}
Areal perspective is related with Occlusion: Objects far away from the viewer are often occluded by the atmosphere, be it air, smoke, fog or water. Consequentially, objects far away change their appeared color, losing saturation, and chroma.
Unlike most depth cues, it gets more effective as the distance from the observer increases.

\paragraph{Reproduction}
Reproducing this cue requires extra work. A common approach is to mix the object color with a fog color, depending on it's distance to the observer. This is cheap, and can be enabled per object\cite{fog}. Weights of the mixing is determined by a fog equation.

\paragraph{Non-reproduction}
Not reproducing this clue is easy, and it is not enabled by default. Explicit control over the appeared depth can be achieved by individually changing the fog equation for each object.


\subsubsection{Accomodation}
\paragraph{Description}
Accommodation is the change in the shape of the lens of the eye, to keep the perceived image of the world sharp\cite{accommodation}. It is coupled with convergence. Viewing stereoscopic material requires that the accommodation stays the same, since all image information comes from a screen at a fixed depth.

\paragraph{Reproduction}
Artificially generating the requirement that the human eye changes accommodation is hard. It requires optics in between the eye and the screen, or the changing of distance to screen depending on the object that is focused. Neither is practical to do interactive.

\paragraph{Non-reproduction}
Not reproducing this cue is almost required. Everything seen on a screen requires the same accommodation to be viewed as the screen itself. If a constant accommodation requirement throughout the scene exists, a screen at a huge distance, or a convex screen can be used.


\subsubsection{Light and Shading}
\paragraph{Description}
Shading and lighting is a strong cue for depth inside of objects. Shadows, or varying light intensities based on the angle to the light source all fall in this category.
Shadows are created by objects obstructing the light from falling onto an object. The shape depends on the position and shape of the obstructing object, the target, and the light source. Creating shadows is a hard problem in real time computer graphics.
Shading an object is coloring it based on the amount of light that falls on it's surface. This depends on the type, distance and shape of the light source, and the angle of incident on the surface, and is easily approximated even in real time computer graphics.

\paragraph{Reproduction}
Shading can be enabled and disabled per object, or even per vertex.
Shadows require more work, and it depends on the algorithm used for creating them how easy it is to add one to a scene.
Creating shadows on planar surfaces are easier than shadows on arbitrary shapes.

\paragraph{Non-reproduction}
Removing a shadow is hard, but not creating one is easy, so this is the recommended course of action.

\begin{table*}[p]
\begin{center}
\small
\begin{tabular}{p{2cm}|p{1.9cm}|p{5cm}|p{5cm}}
Cue & Family & Created by & Removed by \\
\hline
Relative Size &
Projection &
Perspective Projection or non uniform scaling as a function of distance to camera &
Parallel projection or non uniform scaling as a function of distance to camera \\
Relative Density &
Projection &
Perspective Projection or non uniform scaling of space and objects, or translation and scaling of objects as a function of distance to camera &
Parallel Projection or non uniform scaling of space and objects, or translation and scaling of objects as a function of distance to camera \\
Motion Perspective &
Projection &
Perspective Projection, scaling of space, or adjusting velocity of objects as function of camera distance &
Parallel Projection, scaling of space, or adjusting velocity of objects as function of camera distance \\
Height of visual field &
Projection &
Perspective Projection, an angled projection, angled camera, translating/shearing as function of distance to camera &
Parallel projection with camera parallel to ground plane, vertical translation/shearing as function of camera distance \\
Convergence &
Projection &
Two cameras with separation, either converged, perspective, or both. Or horizontal translation/shearing as function of distance to camera and camera direction &
Only one camera, parallel projection, horizontal translation/shearing as function of distance to camera and camera direction \\
Binocular stereopsis &
Projection &
Two cameras with separation, either converged, perspective, or both. Or horizontal translation/shearing as function of distance to camera and camera direction &
Only one camera, parallel projection, horizontal translation/shearing as function of distance to camera and camera direction \\
Occlusion &
Physical &
Depth ordering, Depth buffering &
Depth ordering, Blending \\
Aerial perspective &
Physical &
Fog Equation &
Not using Fog Equation \\
Accom\-modation &
Optical &
Adaptive optics, placing objects/screen at varying distances from viewer &
Default behaviour, whole screen requires at approximately the same accommodation \\
Light \& Shading &
Physical &
Light Equation, Shadow projection, shadow maps &
Not using Light Equation, Shadow projection or shadow maps
\end{tabular}
\end{center}
\caption{List of cues with a short summary on how to create and remove them}
\label{DepthCuesTable}
\end{table*}
