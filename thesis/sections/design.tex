\section{Design\label{Design}}
\paragraph{}
Implementing a flexible and powerful framework for user testing of stereoscopic problems requires a design that accounts for some special requirements. To find out what those requirements are, several tests where designed and executed. The design of the application was adapted to be fit for use in those and many other imaginable tests.

\paragraph{Creation}
The framework is split into three parts: The test design part aids with the construction of the test scene. A scene is a description of stimuli, possible inputs, and reactions to them. Traditional tests in this area show a series of pictures, requiring user feedback for each, while measuring the response time and the correctness. Stimuli are often precomputed and only consist of a single pixel image.

The requirements for stereoscopic test are different: It is not feasible to manually prepare stimuli, especially if complexe interaction is required. A method to generate them on the fly is needed.
Section \ref{sceneRep} describes how the look of a scene could be represented.

\paragraph{Testing}
The testing part is the most important. It displays stimuli and logs the user replies, reacting in a way that is defined by the designer of the test. While traditional tests only follow the question-response pattern, stereoscopic user tests often require more: Trials often have to be randomized with several constraints, simply randomizing might lead to overlaps, or imbalances in dependent properties. All parameters of the stimulus have to be directly or indirectly controllable based on user input such as movement of stimuli, movement of the camera, or visibility of objects.

\paragraph{Analysis}
Analysing the gathered data is the third part. This is usually done in a combinataion of \textit{Microsoft Excel} and highly specialized data analysation methods such as Anova. Both are sophisticated and well known by the users.

The easiest way to achieve compatibility with the known procedures is to produce data in a format, that is evaluatable in those tools. A log transformation program can take care of this in most tests: The time stamp based logs get parsed, and challenge-response times get measured and written in a format importable by spread sheet applications.
For more flexible data access, it can be imported into a database, where standard \textit{SQL} queries can be used to select subsets of the data, sorted and filtered in many ways.

Some tests might not follow this pattern, and the data has to be analysed in a different way.


\subsection{Representation of a Scene\label{sceneRep}}
\paragraph{}
\textit{Scene graphs} are used to store scenes in a structured way. They have been continually developed since their invention\cite{scenegraph} to account for spatial, state, hierarchy and other properties.
Many scene graph libraries exist, but they are usually focused on a specific field, and part of a bigger framework.

To be able to control inconsistencies such as individual depth cues, it is required that the scene graph can represent these. Nodes could add or remove cues for their children, giving a maximum of control to the users. Scene graph libraries do not support those requirements. Designing a simple scene graph is required.

\subsubsection{Node types}
\paragraph{}
Scene graphs are tree structures consisting of nodes with zero or more child nodes. The scene itself is typically the root node, while actual rendered objects often are leaves. The following nodes are planed to be implemented in the framework.

\begin{description}
\item[Rectangle] A primitive geometry node, which has the shape of a parallelogram. The node can reference a texture, which gets mapped on it's surface.
\item[Parallelepiped] A primitive geometry node, which has the shape of a parallelepiped (parallelogram prism). As it's parent it can be textured.
\item[Pixelplane] A primitive geometry node. It is used to draw pixel exact images at any position in space. It requires a texture to be visible. Pixelplanes are point shaped, and therefore are not influenced by scaling and rotation.
\item[Text] A primitive geometry node. It draws text at any position in space, similar to Pixelplanes.
\item[Mesh] A primitive geometry node who's geometry is defined by a mesh. The mesh can contain vertex normals and vertex texture coordinates. A texture can be mapped on the object. It might be desirable to also include vertex color.
\item[AffineTransformation] A group  node. It contains other nodes, which it can affine transform by directly manipulating the matrix stack.
\item[Camera] A group node. It contains other nodes, which are rendered by this camera instead of the global camera. This is used to control projection cues in a consistent way. Has to reset the depth buffer.
\item[DepthBuffer] A group node. Disables or enables the use of the depth buffer for all contained elements. This is used to disable occlusion clues. Can reset the depth buffer.
\item[Lighting] A group node. Enables lighting and a light source with controllable parameters for all sub nodes. This is used to enable lighting depth cues.
\item[Atmosphere] A group node. Enables the fog equation and controls its parameters. This is used to enable aerial depth cues.
\end{description}

\paragraph{}
The following nodes are problematic and might be hard to use, implement and understand due to their side effects.

\begin{description}
\item[XSize] A group node that scales objects to add or remove depth cues caused by perspective projection. It can be implemented on object (scale object individually, without consider intra object depth) or space level (scale  as function of depth, which is similar to a camera projection). Either way has it's own problems.
\item[XOffsest] A group node that moves objects it contains as function of their camera distance. Can be used to add or remove height-of-field, convergence or motion parallax cues.
\end{description}

\subsubsection{Node organisation}
\paragraph{}
Nodes are the building blocks of a scene graph, but how they are put together is similarly important. Due to the requirements of some nodes to clear the depth buffer, and the DepthBuffer node, the order of objects in a group node has to be in the desired order of drawing, not insertion.

Since most advanced functionality is designed to be in group nodes, objects have to be grouped based on their semantics. Those are drawn perspectively in the same camera node, all that have the be lit in a lighting node, and so on. For some nodes this is required for them to work, for others it is just a matter of performance.

To increase performance in complex scenes it might be desirable to use a spatially organized tree. Instead of grouping by state (such as camera, lighting), grouping would be done by proximity. This allows for faster culling. To get both functionalities, parallel trees have to be built. An object would reside in both trees. But so far, scene complexity is intended to be very low, so this optimisation is unlikely to be needed.


\subsection{Mechanics of a Scene\label{sceneMech}}
\paragraph{}
Having a scene with the desired visualisation is not enough. To conduct a test, the scene has to react to user input, to timers and has to be able to modify the scene graph. Logging has to be unconstrained. Randomisation and random permutations require a state.

\subsubsection{``Programming'' a scene}
\paragraph{}
The solution to all those problems is to use a programming language to define the scene mechanics. Anything that can be computed is assumed to be computable with a language that is \textit{turing complete}\cite{turing}. Using such a language would not limit the possibilities of the user, while making designing the scene much easier, faster and less error prone than writing a dedicated tool.

\subsubsection{Procedual API}
\paragraph{}
\textit{Procedural languages} are turing complete, so embedding a language would give all the computational flexibility needed. The same methods to build a scene graph and change object properties within \textit{C++} code can also be used in the scene mechanics. Proxy objects can mediate between the embedded language and the \textit{C++} API.

Creating scenes this way follows standard programming paradigmas, and someone who can program in a procedural language should have little problems adapting to what ever syntax the embedded language uses. The drawback of this approach is, that someone who does not have programming experience will find creating a scene rather unintuitive.

\subsubsection{State API}
\paragraph{}
A more user friendly approach is \textit{Visual Programming}, a class of languages that are based on a visual instead of a textual representation of programs. Visual languages are used in data acquisition tools such as \textit{National Instruments}' \textit{LabVIEW}, music studio software such as \textit{Cycling '74}'s \textit{Max/MSP} or scripting tools like \textit{Apple}'s \textit{Automator}.
The pattern used in those languages is that of \textit{Dataflow-Programming}\cite{dataflow}. Unfortunately, it does not fit into the requirements of the testing tool.

Popular graphic languages in education are \textit{Finite State Machines}\cite{fsm}. They are easy to describe mathematically, and are rather intuitive, compared to traditional programming languages.
The original \textit{LEGO} \textit{Mindstorms} used a flow chart based language that is loosely related with Finite State Machines, and managed to appeal even to young people without programming experience.

A finite state machine is an algorithm that is described as set of states, and state transitions. The transitions can follow various rules, but the most common are based on input. A transition can also write output, or do various other things, depending on the type of state machine.

The original turing machine is a finite state machine that can also write on a so called ``tape''.

